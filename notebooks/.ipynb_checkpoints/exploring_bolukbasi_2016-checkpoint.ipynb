{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from L101_utils.data_paths import wikift, bolu_gender_specific, bolu_equalize_pairs, googlew2v, bolu_definitional_pairs\n",
    "from L101_utils.mock_model import MockModel\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for i, line in enumerate(fin):\n",
    "        if i == 100000: break\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.asarray(list(map(float, tokens[1:])))\n",
    "        data[tokens[0]] /=  np.linalg.norm(data[tokens[0]]) \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\users\\\\user\\\\desktop\\\\coursework\\\\nlp\\\\l101_bias_space_study\\\\data\\\\GoogleNews-vectors-negative300'] bin\n"
     ]
    }
   ],
   "source": [
    "emb = MockModel.from_file(googlew2v, mock=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def get_pc_projection_boluk(X, k=1, mean_rev=True):\n",
    "    mean_rev = int(mean_rev)\n",
    "    n, d = X.shape\n",
    "    X = X - mean_rev * X.mean(axis=0)\n",
    "    C = (X.T.dot(X) / n)\n",
    "    D, V = la.eigh(C)\n",
    "    V = V[:, :k]\n",
    "    return V.dot(V.T)\n",
    "\n",
    "\n",
    "def create_nu_boluk(X, P):\n",
    "    mu = X.mean(axis=0)\n",
    "    nu = mu - P.dot(mu)\n",
    "    return nu, P.dot(mu)\n",
    "\n",
    "\n",
    "def equalize_boluk(E, P, N=None, debug=True):\n",
    "    \n",
    "    nu, mu_b = create_nu(E, P)\n",
    "    if debug:\n",
    "        print(np.linalg.norm(E, axis=1))\n",
    "    \n",
    "    E = E.dot(P) - 1 * mu_b\n",
    "    \n",
    "    if debug:\n",
    "        print(np.linalg.norm(E, axis=1))\n",
    "#         plt.imshow(np.abs(P))\n",
    "        print(np.min(P.ravel()), np.max(P.ravel()))\n",
    "\n",
    "    E /= np.linalg.norm(E, axis=1)[..., None]\n",
    "    \n",
    "    v = np.linalg.norm(nu)\n",
    "    fac = np.sqrt(1 - v**2)\n",
    "    remb = nu +  fac * E\n",
    "    \n",
    "    if debug:\n",
    "        print(np.linalg.norm(E,axis=1))\n",
    "        print(np.linalg.norm(remb, axis=1))\n",
    "    \n",
    "    return remb, E\n",
    "\n",
    "\n",
    "def neutralise_boluk(X, P):\n",
    "    print(\"start neutralise\")\n",
    "    I = np.eye(P.shape[0])\n",
    "    out =  X.dot( (I - P).T )\n",
    "    print(\"done matrix mult (neutralise)\", out.shape)\n",
    "    return out\n",
    "\n",
    "\n",
    "def generate_subspace_projection(emb,\n",
    "                                 pair_file=bolu_definitional_pairs,\n",
    "                                 n_components=1):\n",
    "    with open(pair_file, \"r\") as f:\n",
    "        pairs = json.load(f)\n",
    "    \n",
    "    matrix = []\n",
    "    for a, b in pairs:\n",
    "        center = (emb[a.lower()] + emb[b.lower()])/2\n",
    "        matrix.append(emb[a.lower()] - center)\n",
    "        matrix.append(emb[b.lower()] - center)\n",
    "        \n",
    "    matrix = np.asarray(matrix)\n",
    "    P = get_pc_projection_boluk(matrix, k=n_components)\n",
    "    \n",
    "    return P\n",
    "\n",
    "\n",
    "def hard_debiase(emb,\n",
    "                 gender_specific_file=bolu_gender_specific,\n",
    "                 equalize_pair_file=bolu_equalize_pairs,\n",
    "                 def_pair_file=bolu_definitional_pairs,\n",
    "                 n_components=1):\n",
    "    \n",
    "#     emb = deepcopy(emb)\n",
    "    \n",
    "    print(\"projection started\")\n",
    "    P = generate_subspace_projection(emb, def_pair_file, n_components)\n",
    "    print(\"projection done\")\n",
    "    \n",
    "    with open(gender_specific_file, \"r\") as f:\n",
    "        gendered_words = set(json.load(f))\n",
    "    \n",
    "    print(\"neutralisation started\")\n",
    "    all_words = set(emb.vocab.keys())\n",
    "    neutral_words = all_words - gendered_words\n",
    "    print(\"getting indices should be fast\")\n",
    "    indices = [emb.vocab[k].index for k in neutral_words]\n",
    "    print(\"created neutral word set\", len(neutral_words))\n",
    "    import pdb; pdb.set_trace()\n",
    "    neutral = emb.vectors[indices]\n",
    "    print(\"done indexing into neutral embs\")\n",
    "    test = neutralise_boluk(neutral)\n",
    "    emb[indices] = test\n",
    "    print(\"neutralisation done\")\n",
    "    \n",
    "    with open(bolu_equalize_pairs, \"r\") as f:\n",
    "        equalize_words = set(json.load(f))\n",
    "    \n",
    "    candidates = {x for e1, e2 in equalize_words for x in [(e1.lower(), e2.lower()),\n",
    "                                                           (e1.title(), e2.title()),\n",
    "                                                           (e1.upper(), e2.upper())]}\n",
    "    print(candidates, \"started equalising\")\n",
    "    for (e1, e2) in candidates:\n",
    "        if (e1 in all_words and e2 in all_words):\n",
    "            remb, _ = equalize_boluk(emb[[e1,e2]], P)\n",
    "            emb[[e1,e2]] = remb\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projection started\n",
      "projection done\n",
      "neutralisation started\n",
      "getting indices should be fast\n",
      "created neutral word set 2998559\n",
      "> <ipython-input-4-a8ca77624351>(94)hard_debiase()\n",
      "-> neutral = emb.vectors[indices]\n",
      "(Pdb) neutral = emb.vectors[indices]\n",
      "*** IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n",
      "(Pdb) len(indices)\n",
      "2998559\n",
      "(Pdb) indices = [emb.vocab[k.lower()] for k in neutral_words if k.lower() in emb.vocab]\n",
      "(Pdb) len(indices)\n",
      "662397\n",
      "(Pdb) indices = [emb.vocab[k] for k in neutral_words if k in emb.vocab]\n",
      "(Pdb) len(indices)\n",
      "2998559\n",
      "(Pdb) indices[0:10]\n",
      "[<gensim.models.keyedvectors.Vocab object at 0x00000225A0BCD208>, <gensim.models.keyedvectors.Vocab object at 0x00000225A5264548>, <gensim.models.keyedvectors.Vocab object at 0x00000225AA4A0508>, <gensim.models.keyedvectors.Vocab object at 0x00000225AEB7D4C8>, <gensim.models.keyedvectors.Vocab object at 0x00000225A866DC08>, <gensim.models.keyedvectors.Vocab object at 0x00000225924E28C8>, <gensim.models.keyedvectors.Vocab object at 0x00000225AD49FDC8>, <gensim.models.keyedvectors.Vocab object at 0x0000022598AE4C88>, <gensim.models.keyedvectors.Vocab object at 0x00000225A0FFCF88>, <gensim.models.keyedvectors.Vocab object at 0x00000225AA311488>]\n",
      "(Pdb) indices = [emb.vocab[k].index for k in neutral_words if k in emb.vocab]\n",
      "(Pdb) indices[0:10]\n",
      "[1517805, 1094750, 1379359, 2829246, 1131273, 151840, 1374413, 420165, 864170, 1221888]\n",
      "(Pdb) neutral = emb.vectors[indices]\n"
     ]
    }
   ],
   "source": [
    "embnasius = hard_debiase(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb[set([\"hello\", \"punk\"])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_vectors(wikift);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_dat = \"\"\"he, her, his, she, him, man, women, men, woman, spokesman, wife, himself, son, mother, father, chairman,\n",
    "daughter, husband, guy, girls, girl, boy, boys, brother, spokeswoman, female, sister, male, herself, brothers, dad,\n",
    "actress, mom, sons, girlfriend, daughters, lady, boyfriend, sisters, mothers, king, businessman, grandmother,\n",
    "grandfather, deer, ladies, uncle, males, congressman, grandson, bull, queen, businessmen, wives, widow,\n",
    "nephew, bride, females, aunt, prostate cancer, lesbian, chairwoman, fathers, moms, maiden, granddaughter,\n",
    "younger brother, lads, lion, gentleman, fraternity, bachelor, niece, bulls, husbands, prince, colt, salesman, hers,\n",
    "dude, beard, filly, princess, lesbians, councilman, actresses, gentlemen, stepfather, monks, ex girlfriend, lad,\n",
    "sperm, testosterone, nephews, maid, daddy, mare, fiance, fiancee, kings, dads, waitress, maternal, heroine,\n",
    "nieces, girlfriends, sir, stud, mistress, lions, estranged wife, womb, grandma, maternity, estrogen, ex boyfriend,\n",
    "widows, gelding, diva, teenage girls, nuns, czar, ovarian cancer, countrymen, teenage girl, penis, bloke, nun,\n",
    "brides, housewife, spokesmen, suitors, menopause, monastery, motherhood, brethren, stepmother, prostate,\n",
    "hostess, twin brother, schoolboy, brotherhood, fillies, stepson, congresswoman, uncles, witch, monk, viagra,\n",
    "paternity, suitor, sorority, macho, businesswoman, eldest son, gal, statesman, schoolgirl, fathered, goddess,\n",
    "hubby, stepdaughter, blokes, dudes, strongman, uterus, grandsons, studs, mama, godfather, hens, hen, mommy,\n",
    "estranged husband, elder brother, boyhood, baritone, grandmothers, grandpa, boyfriends, feminism, countryman,\n",
    "stallion, heiress, queens, witches, aunts, semen, fella, granddaughters, chap, widower, salesmen, convent,\n",
    "vagina, beau, beards, handyman, twin sister, maids, gals, housewives, horsemen, obstetrics, fatherhood,\n",
    "councilwoman, princes, matriarch, colts, ma, fraternities, pa, fellas, councilmen, dowry, barbershop, fraternal,\n",
    "ballerina\"\"\"\n",
    "\n",
    "biased_dat = biased_dat.replace(\" \",\"\").replace(\"\\n\",\"\").strip(\"\\r\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = [X[k]  for k in biased_dat if k in X]\n",
    "N = [X[k]  for k in set(X.keys()) - set(biased_dat) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.array(G)\n",
    "N = np.array(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = get_pc_projection(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nv = neutralise(N, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nv /= np.linalg.norm(Nv, axis=1)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pc_projection(X, k=1):\n",
    "    n, d = X.shape\n",
    "    X = X - X.mean(axis=0)\n",
    "    C = (X.T.dot(X) / n)\n",
    "    D, V = la.eigh(C)\n",
    "    V = V[:, :k]\n",
    "    return V.dot(V.T)\n",
    "\n",
    "def create_nu(X, P):\n",
    "    mu = X.mean(axis=0)\n",
    "    nu = mu - P.dot(mu)\n",
    "    return nu, P.dot(mu)\n",
    "\n",
    "def equalize(E, P, N=None, debug=True):\n",
    "    \n",
    "    nu, mu_b = create_nu(E, P)\n",
    "#     print(E[0,:] == E[1,:])\n",
    "    if debug:\n",
    "        print(np.linalg.norm(E, axis=1))\n",
    "    \n",
    "    E = E.dot(P) - 0 * mu_b\n",
    "    \n",
    "    if debug:\n",
    "        print(np.linalg.norm(E, axis=1))\n",
    "        plt.imshow(np.abs(P))\n",
    "        print(np.min(P.ravel()), np.max(P.ravel()))\n",
    "\n",
    "    E /= np.linalg.norm(E, axis=1)[..., None]\n",
    "    \n",
    "    v = np.linalg.norm(nu)\n",
    "    fac = np.sqrt(1 - v**2)\n",
    "    remb = nu +  fac * E\n",
    "    \n",
    "    if debug:\n",
    "        print(np.linalg.norm(E,axis=1))\n",
    "        print(np.linalg.norm(remb, axis=1))\n",
    "    \n",
    "    return remb, E\n",
    "\n",
    "def neutralise(X, P):\n",
    "    \n",
    "    return X.dot((np.eye(P.shape[0]) - P))\n",
    "\n",
    "# Make equaliser set out of : he, his, her, she, him, man, women, men, woman\n",
    "E = G[0:9, :]\n",
    "\n",
    "Eveq, E = equalize(E, P, Nv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eveq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eveq.dot(Nv[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(Eveq, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    print((np.sign(Eveq[0,:]) == np.sign(Eveq[i,:]) ).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = P.dot(E[0,:].T)\n",
    "n = (np.eye(P.shape[0]) - P).dot(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.dot(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.abs(P))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(P == P.T).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(P).max(), np.diag(P).min(), (P - np.diag(np.diag(P))).max(), np.diag(np.abs(P)).max(), np.min(P), np.max(P), np.std(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = G.shape\n",
    "Gc  = G - G.mean(axis=0)\n",
    "C = (Gc.T.dot(Gc) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.abs(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
